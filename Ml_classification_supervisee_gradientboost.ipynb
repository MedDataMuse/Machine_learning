{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a6f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# SCRIPT 2 — CLASSIFICATION SUPERVISÉE (SAheart)\n",
    "# ======================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from patsy import dmatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f0bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 1) LECTURE + PREP\n",
    "# ======================================================================\n",
    "\n",
    "don = pd.read_csv(\"SAheart.data\", sep=\",\")\n",
    "don = don.rename(columns={\"chd\": \"Y\"})\n",
    "don = don.drop(columns=[\"row.names\"])\n",
    "\n",
    "Y = don[\"Y\"].to_numpy()\n",
    "\n",
    "# design matrix\n",
    "nomsvar = list(don.columns.difference([\"Y\"]))\n",
    "formule = \"~\" + \"+\".join(nomsvar)\n",
    "dsX = dmatrix(formule, don)\n",
    "X = np.asarray(dsX)[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07a24207",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 2) BLOCS VC EXTERNE\n",
    "# ======================================================================\n",
    "nb = 10\n",
    "tmp = np.arange(don.shape[0]) % nb\n",
    "rng = np.random.default_rng(seed=1234)\n",
    "bloc = rng.choice(tmp, size=don.shape[0], replace=False)\n",
    "\n",
    "PROB = pd.DataFrame({\n",
    "    \"bloc\": bloc,\n",
    "    \"Y\": don[\"Y\"],\n",
    "    \"log\": 0.0,\n",
    "    \"lasso\": 0.0,\n",
    "    \"ridge\": 0.0,\n",
    "    \"elast\": 0.0\n",
    "})\n",
    "\n",
    "# Grille pour pénalisation\n",
    "def grille(X, y, type=\"lasso\", ng=400):\n",
    "    scalerX = StandardScaler().fit(X)\n",
    "    Xcr = scalerX.transform(X)\n",
    "    l0 = np.abs(Xcr.T.dot((y - y.mean()))).max() / X.shape[0]\n",
    "    llc = np.linspace(0, -4, ng)\n",
    "    if type == \"lasso\":\n",
    "        Cs = 1 / 0.9 / X.shape[0] / (l0 * 10**llc)\n",
    "    elif type == \"ridge\":\n",
    "        Cs = 1 / 0.9 / X.shape[0] / ((l0 * 10**llc) * 100)\n",
    "    elif type == \"enet\":\n",
    "        Cs = 1 / 0.9 / X.shape[0] / ((l0 * 10**llc) * 2)\n",
    "    return Cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b0133f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Bloc 0 ###\n",
      "\n",
      "### Bloc 1 ###\n",
      "\n",
      "### Bloc 2 ###\n",
      "\n",
      "### Bloc 3 ###\n",
      "\n",
      "### Bloc 4 ###\n",
      "\n",
      "### Bloc 5 ###\n",
      "\n",
      "### Bloc 6 ###\n",
      "\n",
      "### Bloc 7 ###\n",
      "\n",
      "### Bloc 8 ###\n",
      "\n",
      "### Bloc 9 ###\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 3) VC EXTERNE\n",
    "# ======================================================================\n",
    "\n",
    "for i in range(nb):\n",
    "    print(f\"\\n### Bloc {i} ###\")\n",
    "\n",
    "    Xapp = X[bloc != i, :]\n",
    "    Xtest = X[bloc == i, :]\n",
    "    Yapp = don[bloc != i][\"Y\"]\n",
    "    Ytest = don[bloc == i][\"Y\"]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # MODELE 1 : Logistique sans pénalisation\n",
    "    # -----------------------------------------\n",
    "    log = LogisticRegression(penalty=None, solver=\"newton-cholesky\").fit(Xapp, Yapp)\n",
    "    PROB.loc[PROB.bloc == i, \"log\"] = log.predict_proba(Xtest)[:, 1]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # MODELE 2 : LASSO\n",
    "    # -----------------------------------------\n",
    "    Cs_lasso = grille(Xapp, Yapp, \"lasso\")\n",
    "    lassocv = LogisticRegressionCV(\n",
    "        cv=10, penalty=\"l1\", solver=\"saga\", Cs=Cs_lasso, max_iter=2000\n",
    "    )\n",
    "    pipe_lasso = Pipeline([(\"cr\", StandardScaler()), (\"lassocv\", lassocv)])\n",
    "    pipe_lasso.fit(Xapp, Yapp)\n",
    "    PROB.loc[PROB.bloc == i, \"lasso\"] = pipe_lasso.predict_proba(Xtest)[:, 1]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # MODELE 3 : RIDGE\n",
    "    # -----------------------------------------\n",
    "    Cs_ridge = grille(Xapp, Yapp, \"ridge\")\n",
    "    ridgecv = LogisticRegressionCV(\n",
    "        cv=10, penalty=\"l2\", solver=\"saga\", Cs=Cs_ridge, max_iter=2000\n",
    "    )\n",
    "    pipe_ridge = Pipeline([(\"cr\", StandardScaler()), (\"ridgecv\", ridgecv)])\n",
    "    pipe_ridge.fit(Xapp, Yapp)\n",
    "    PROB.loc[PROB.bloc == i, \"ridge\"] = pipe_ridge.predict_proba(Xtest)[:, 1]\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # MODELE 4 : ELASTIC NET\n",
    "    # -----------------------------------------\n",
    "    Cs_enet = grille(Xapp, Yapp, \"enet\")\n",
    "    enetcv = LogisticRegressionCV(\n",
    "        cv=10, penalty=\"elasticnet\", solver=\"saga\", l1_ratios=[0.5],\n",
    "        Cs=Cs_enet, max_iter=2000\n",
    "    )\n",
    "    pipe_enet = Pipeline([(\"cr\", StandardScaler()), (\"enetcv\", enetcv)])\n",
    "    pipe_enet.fit(Xapp, Yapp)\n",
    "    PROB.loc[PROB.bloc == i, \"elast\"] = pipe_enet.predict_proba(Xtest)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d95555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AUC ===\n",
      "    AUC_log  AUC_lasso  AUC_ridge  AUC_elast\n",
      "0  0.771151   0.764342   0.773634   0.769785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 4) PERFORMANCE GLOBALE (AUC)\n",
    "# ======================================================================\n",
    "\n",
    "tab_auc = pd.DataFrame({\n",
    "    \"AUC_log\":   [roc_auc_score(PROB[\"Y\"], PROB[\"log\"])],\n",
    "    \"AUC_lasso\": [roc_auc_score(PROB[\"Y\"], PROB[\"lasso\"])],\n",
    "    \"AUC_ridge\": [roc_auc_score(PROB[\"Y\"], PROB[\"ridge\"])],\n",
    "    \"AUC_elast\": [roc_auc_score(PROB[\"Y\"], PROB[\"elast\"])]\n",
    "})\n",
    "\n",
    "print(\"\\n=== AUC ===\")\n",
    "print(tab_auc)\n",
    "\n",
    "# Sauvegarde\n",
    "PROB.to_csv(\"PROB_classif.csv\", index=False)\n",
    "tab_auc.to_csv(\"perf_classif.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720d6ba2",
   "metadata": {},
   "source": [
    "# ARBRE DE DECISION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8abe3b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "for i in np.arange(nb):\n",
    "    print(i)\n",
    "    Xapp = X[bloc!=i,:]\n",
    "    Xtest = X[bloc==i,:]\n",
    "    Yapp = don[bloc!=i][\"Y\"]\n",
    "    Ytest = don[bloc==i][\"Y\"]\n",
    "    #### arbre\n",
    "    arbre = DecisionTreeClassifier(min_samples_leaf=5)\n",
    "    arbre.fit(Xapp,Yapp)\n",
    "    PROB.loc[PROB.bloc==i,\"arbre\"] = arbre.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd064477",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dac24191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for i in np.arange(nb):\n",
    "    print(i)\n",
    "    Xapp = X[bloc!=i,:]\n",
    "    Xtest = X[bloc==i,:]\n",
    "    Yapp = don[bloc!=i][\"Y\"]\n",
    "    ##### Foret\n",
    "    foret = RandomForestClassifier()\n",
    "    foret.fit(Xapp,Yapp)\n",
    "    PROB.loc[PROB.bloc==i,'foret100'] = foret.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd0602",
   "metadata": {},
   "source": [
    "# GRADIENT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e21438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "params = dict(max_iter=1000, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "hgbm = HistGradientBoostingClassifier(**params)\n",
    "for i in np.arange(nb):\n",
    "    print(i)\n",
    "    Xapp = X[bloc!=i,:]\n",
    "    Xtest = X[bloc==i,:]\n",
    "    Yapp = don[bloc!=i][\"Y\"]\n",
    "    ##### Foret\n",
    "    hgbm.fit(Xapp,Yapp)\n",
    "    PROB.loc[PROB.bloc==i,'hgbm'] = hgbm.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06981949",
   "metadata": {},
   "source": [
    "# ADA BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fbfeb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "params = dict(n_estimators=1000, learning_rate=0.1, random_state=42)\n",
    "ada = AdaBoostClassifier(**params)\n",
    "for i in np.arange(nb):\n",
    "    print(i)\n",
    "    Xapp = X[bloc!=i,:]\n",
    "    Xtest = X[bloc==i,:]\n",
    "    Yapp = don[bloc!=i][\"Y\"]\n",
    "    ##### Foret\n",
    "    ada.fit(Xapp,Yapp)\n",
    "    PROB.loc[PROB.bloc==i,'ada1'] = ada.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b179ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "1\n",
      "29\n",
      "2\n",
      "18\n",
      "3\n",
      "23\n",
      "4\n",
      "21\n",
      "5\n",
      "15\n",
      "6\n",
      "17\n",
      "7\n",
      "16\n",
      "8\n",
      "14\n",
      "9\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "params = dict(n_estimators=1000, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "gbm = GradientBoostingClassifier(\n",
    "    **params,\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    ")\n",
    "for i in np.arange(nb):\n",
    "    print(i)\n",
    "    Xapp = X[bloc!=i,:]\n",
    "    Xtest = X[bloc==i,:]\n",
    "    Yapp = don[bloc!=i][\"Y\"]\n",
    "    ##### Foret\n",
    "    gbm.fit(Xapp,Yapp)\n",
    "    print(gbm.n_estimators_)\n",
    "    PROB.loc[PROB.bloc==i,'xgb5'] = gbm.predict_proba(Xtest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0457fd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          seuil     tn     tp    fn    fp  sensitivity  specificity  sen+spe  \\\n",
      "Y           0.5  302.0  160.0   0.0   0.0        1.000        1.000    2.000   \n",
      "log         0.5  251.0   81.0  79.0  51.0        0.506        0.831    1.337   \n",
      "lasso       0.5  264.0   73.0  87.0  38.0        0.456        0.874    1.330   \n",
      "ridge       0.5  263.0   73.0  87.0  39.0        0.456        0.871    1.327   \n",
      "elast       0.5  267.0   70.0  90.0  35.0        0.438        0.884    1.322   \n",
      "arbre       0.5  214.0   82.0  78.0  88.0        0.512        0.709    1.221   \n",
      "foret100    0.5  247.0   68.0  92.0  55.0        0.425        0.818    1.243   \n",
      "ada1        0.5  262.0   77.0  83.0  40.0        0.481        0.868    1.349   \n",
      "xgb5        0.5  245.0   67.0  93.0  57.0        0.419        0.811    1.230   \n",
      "hgbm        0.5  229.0   63.0  97.0  73.0        0.394        0.758    1.152   \n",
      "\n",
      "          accuracy  \n",
      "Y            1.000  \n",
      "log          0.719  \n",
      "lasso        0.729  \n",
      "ridge        0.727  \n",
      "elast        0.729  \n",
      "arbre        0.641  \n",
      "foret100     0.682  \n",
      "ada1         0.734  \n",
      "xgb5         0.675  \n",
      "hgbm         0.632  \n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sklm\n",
    "noms = PROB.columns[1:]\n",
    "matsB = pd.DataFrame({\"seuil\": pd.Series(0.0, index=noms)})\n",
    "s = .5\n",
    "for nom in noms:\n",
    "    matsB.loc[nom,\"seuil\"] = s\n",
    "    confmat = sklm.confusion_matrix(PROB.Y, PROB.loc[:,nom]>=s)\n",
    "    matsB.loc[nom, \"tn\"] = confmat[0,0]\n",
    "    matsB.loc[nom, \"tp\"] = confmat[1,1]\n",
    "    matsB.loc[nom, \"fn\"] = confmat[1,0]\n",
    "    matsB.loc[nom, \"fp\"] = confmat[0,1]\n",
    "    matsB.loc[nom,\"sensitivity\"] = confmat[1,1]/(confmat[1,1]+confmat[1,0])\n",
    "    matsB.loc[nom,\"specificity\"] = confmat[0,0]/(confmat[0,0]+confmat[0,1])\n",
    "    matsB.loc[nom,\"sen+spe\"] = matsB.loc[nom,\"sensitivity\"]+matsB.loc[nom,\"specificity\"]\n",
    "    matsB.loc[nom,\"accuracy\"] = sklm.accuracy_score(PROB.Y, PROB.loc[:,nom]>=s)\n",
    "print(matsB.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
