{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f7a373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# SCRIPT 1 — RÉGRESSION SUPERVISÉE (OZONE)\n",
    "# ======================================================================\n",
    "# Objectif :\n",
    "#   - Préparation données (dummies, scaling…)\n",
    "#   - Modèles : MCO, LASSO, RIDGE, ELASTIC NET\n",
    "#   - Validation croisée interne (choix lambda)\n",
    "#   - Validation croisée externe (prédictions honnêtes)\n",
    "#   - Table finale PREV\n",
    "# ======================================================================\n",
    "\n",
    "# ======================================================================\n",
    "# 0) IMPORTS\n",
    "# ======================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV, Lasso, Ridge, ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3afa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 1) LECTURE + PRÉPARATION DES DONNÉES\n",
    "# ======================================================================\n",
    "\n",
    "don = pd.read_table(\"ozone.txt\", sep=\";\")\n",
    "don = don.rename(columns={\"O3\": \"Y\"})\n",
    "\n",
    "# variables inutiles selon ton workflow\n",
    "don = don.drop(columns=[\"Date\"])\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1A — Codage disjonctif complet (pour référence, même si BASE = sans poly)\n",
    "# ----------------------------------------------------------------------\n",
    "don_dummies = pd.get_dummies(\n",
    "    don,\n",
    "    columns=[\"nebulosite\", \"vent\"],\n",
    "    drop_first=False\n",
    ")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1B — Séparation variables\n",
    "# ----------------------------------------------------------------------\n",
    "X = don_dummies.drop(columns=[\"Y\"])     # variables explicatives\n",
    "Y = don_dummies[\"Y\"].to_numpy()         # cible\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1C — Jeu \"BASE\" = numériques + dummies\n",
    "# ----------------------------------------------------------------------\n",
    "Xbase = X.copy()\n",
    "\n",
    "# Standardisation futur\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd3f35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 2) CRÉATION DES BLOCS — VALIDATION CROISÉE EXTERNE\n",
    "# ======================================================================\n",
    "\n",
    "np.random.seed(1234)\n",
    "nb = 10\n",
    "n = don_dummies.shape[0]\n",
    "\n",
    "tmp = np.arange(n) % nb\n",
    "bloc = np.random.choice(tmp, size=n, replace=False)\n",
    "\n",
    "don_dummies[\"bloc\"] = bloc\n",
    "\n",
    "# Tableau final qui contiendra toutes les prédictions \"honnêtes\"\n",
    "PREV = pd.DataFrame({\n",
    "    \"bloc\": bloc,\n",
    "    \"Y\": Y,\n",
    "    \"MCO\": 0.0,\n",
    "    \"lasso\": 0.0,\n",
    "    \"ridge\": 0.0,\n",
    "    \"elast\": 0.0\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13a4b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Bloc 0 ###\n",
      "\n",
      "### Bloc 1 ###\n",
      "\n",
      "### Bloc 2 ###\n",
      "\n",
      "### Bloc 3 ###\n",
      "\n",
      "### Bloc 4 ###\n",
      "\n",
      "### Bloc 5 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sikal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.278e+00, tolerance: 2.517e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\sikal\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.278e+00, tolerance: 2.517e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Bloc 6 ###\n",
      "\n",
      "### Bloc 7 ###\n",
      "\n",
      "### Bloc 8 ###\n",
      "\n",
      "### Bloc 9 ###\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 3) VALIDATION CROISÉE EXTERNE\n",
    "# ======================================================================\n",
    "\n",
    "for i in range(nb):\n",
    "    print(f\"\\n### Bloc {i} ###\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3.1 — Split TRAIN / TEST\n",
    "    # -----------------------------\n",
    "    Xtrain = Xbase[don_dummies[\"bloc\"] != i]\n",
    "    Xtest  = Xbase[don_dummies[\"bloc\"] == i]\n",
    "\n",
    "    Ytrain = Y[don_dummies[\"bloc\"] != i]\n",
    "    Ytest  = Y[don_dummies[\"bloc\"] == i]\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3.2 — MODELE 1 : MCO\n",
    "    # -----------------------------\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(Xtrain, Ytrain)\n",
    "    prev = reg.predict(Xtest)\n",
    "    PREV.loc[PREV.bloc == i, \"MCO\"] = prev\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3.3 — MODELE 2 : LASSO (VC interne)\n",
    "    # -----------------------------\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "    lassocv = LassoCV(cv=kf, n_alphas=200)\n",
    "\n",
    "    # scaling sur le TRAIN uniquement\n",
    "    scaler_train = StandardScaler().fit(Xtrain)\n",
    "    Xtrain_cr = scaler_train.transform(Xtrain)\n",
    "    Xtest_cr  = scaler_train.transform(Xtest)\n",
    "\n",
    "    lassocv.fit(Xtrain_cr, Ytrain)\n",
    "    lasso = Lasso(alpha=lassocv.alpha_).fit(Xtrain_cr, Ytrain)\n",
    "    PREV.loc[PREV.bloc == i, \"lasso\"] = lasso.predict(Xtest_cr)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3.4 — MODELE 3 : RIDGE (VC interne)\n",
    "    # -----------------------------\n",
    "    alphas_ridge = lassocv.alphas_ * 100  # grille large\n",
    "\n",
    "    ridgecv = RidgeCV(alphas=alphas_ridge, cv=kf)\n",
    "    ridgecv.fit(Xtrain_cr, Ytrain)\n",
    "\n",
    "    ridge = Ridge(alpha=ridgecv.alpha_).fit(Xtrain_cr, Ytrain)\n",
    "    PREV.loc[PREV.bloc == i, \"ridge\"] = ridge.predict(Xtest_cr)\n",
    "\n",
    "    # -----------------------------\n",
    "    # 3.5 — MODELE 4 : ELASTIC NET (VC interne)\n",
    "    # -----------------------------\n",
    "    enetcv = ElasticNetCV(cv=kf, l1_ratio=[0.5], n_alphas=200)\n",
    "    enetcv.fit(Xtrain_cr, Ytrain)\n",
    "\n",
    "    enet = ElasticNet(alpha=enetcv.alpha_, l1_ratio=0.5).fit(Xtrain_cr, Ytrain)\n",
    "    PREV.loc[PREV.bloc == i, \"elast\"] = enet.predict(Xtest_cr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58033f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PERFORMANCE GLOBALE ===\n",
      "    RMSE_MCO  RMSE_LASSO  RMSE_RIDGE  RMSE_ENET\n",
      "0  15.083262   14.899323   14.527871  14.822131\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 4) RÉSULTATS\n",
    "# ======================================================================\n",
    "\n",
    "# RMSE par modèle # je peux demander des voir les autres fonction de perte...\n",
    "def rmse(y, yhat):\n",
    "    return np.sqrt(np.mean((y - yhat)**2))\n",
    "\n",
    "tab_perf = pd.DataFrame({\n",
    "    \"RMSE_MCO\":   [rmse(PREV[\"Y\"], PREV[\"MCO\"])],\n",
    "    \"RMSE_LASSO\": [rmse(PREV[\"Y\"], PREV[\"lasso\"])],\n",
    "    \"RMSE_RIDGE\": [rmse(PREV[\"Y\"], PREV[\"ridge\"])],\n",
    "    \"RMSE_ENET\":  [rmse(PREV[\"Y\"], PREV[\"elast\"])]\n",
    "})\n",
    "\n",
    "print(\"\\n=== PERFORMANCE GLOBALE ===\")\n",
    "print(tab_perf)\n",
    "\n",
    "# Sauvegarde\n",
    "PREV.to_csv(\"PREV_regression_base.csv\", index=False)\n",
    "tab_perf.to_csv(\"perf_regression_base.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
